{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Creating a neural machine translation (NMT) model using Recurrent Neural Networks (RNNs) with TensorFlow involves several steps. Here’s a basic guide on how to implement a sequence-to-sequence (Seq2Seq) model for translation using RNNs. The dataset will be in CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set Up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you have TensorFlow installed. You can install it via pip if you haven't already:\n",
    "### * pip install tensorflow pandas numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to load this data and preprocess it. This involves tokenizing the text, padding sequences, and creating a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('english to bengali.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_caption</th>\n",
       "      <th>bengali_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a child in a pink dress is climbing up a set o...</td>\n",
       "      <td>একটি গোলাপী জামা পরা বাচ্চা মেয়ে একটি বাড়ির প্...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a girl going into a wooden building .</td>\n",
       "      <td>একটি মেয়ে শিশু একটি কাঠের বাড়িতে ঢুকছে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a little girl climbing into a wooden playhouse .</td>\n",
       "      <td>একটি বাচ্চা তার কাঠের খেলাঘরে উঠছে ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a little girl climbing the stairs to her playh...</td>\n",
       "      <td>ছোট মেয়েটি তার খেলার ঘরের সিড়ি বেয়ে উঠছে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a little girl in a pink dress going into a woo...</td>\n",
       "      <td>গোলাপি জামা পড়া ছোট একটি মেয়ে একটি কাঠের তৈরি...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     english_caption                                    bengali_caption\n",
       "0  a child in a pink dress is climbing up a set o...  একটি গোলাপী জামা পরা বাচ্চা মেয়ে একটি বাড়ির প্...\n",
       "1              a girl going into a wooden building .             একটি মেয়ে শিশু একটি কাঠের বাড়িতে ঢুকছে\n",
       "2   a little girl climbing into a wooden playhouse .               একটি বাচ্চা তার কাঠের খেলাঘরে উঠছে ।\n",
       "3  a little girl climbing the stairs to her playh...           ছোট মেয়েটি তার খেলার ঘরের সিড়ি বেয়ে উঠছে\n",
       "4  a little girl in a pink dress going into a woo...  গোলাপি জামা পড়া ছোট একটি মেয়ে একটি কাঠের তৈরি..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "MAX_NUM_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 20\n",
    "EMBEDDING_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add special tokens\n",
    "START_TOKEN = 'startseq'\n",
    "END_TOKEN = 'endseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify target texts to include start and end tokens\n",
    "target_texts = [START_TOKEN + ' ' + text + ' ' + END_TOKEN for text in data['bengali_caption']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad source sequences\n",
    "source_texts = data['english_caption'].tolist()\n",
    "source_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "source_tokenizer.fit_on_texts(source_texts)\n",
    "source_sequences = source_tokenizer.texts_to_sequences(source_texts)\n",
    "source_padded = pad_sequences(source_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad target sequences\n",
    "target_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "target_tokenizer.fit_on_texts(target_texts)\n",
    "target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n",
    "target_padded = pad_sequences(target_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Index for 'startseq': 1\n",
      "Token Index for 'endseq': 2\n"
     ]
    }
   ],
   "source": [
    "# Check if special tokens are in word index\n",
    "print(f\"Token Index for '{START_TOKEN}':\", target_tokenizer.word_index.get(START_TOKEN))\n",
    "print(f\"Token Index for '{END_TOKEN}':\", target_tokenizer.word_index.get(END_TOKEN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(source_padded, target_padded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model parameters\n",
    "num_encoder_tokens = len(source_tokenizer.word_index) + 1\n",
    "num_decoder_tokens = len(target_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Seq2Seq model using RNNs (specifically LSTM or GRU cells) for both the encoder and the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(input_dim=num_encoder_tokens, output_dim=EMBEDDING_DIM)(encoder_inputs)\n",
    "encoder_lstm, state_h, state_c = LSTM(256, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(input_dim=num_decoder_tokens, output_dim=EMBEDDING_DIM)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True)(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_outputs = TimeDistributed(Dense(num_decoder_tokens, activation='softmax'))(decoder_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "489/489 [==============================] - 41s 78ms/step - loss: 2.6719 - accuracy: 0.6225 - val_loss: 1.6645 - val_accuracy: 0.7550\n",
      "Epoch 2/20\n",
      "489/489 [==============================] - 38s 77ms/step - loss: 1.1843 - accuracy: 0.8381 - val_loss: 0.8911 - val_accuracy: 0.8888\n",
      "Epoch 3/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.6933 - accuracy: 0.9142 - val_loss: 0.5904 - val_accuracy: 0.9329\n",
      "Epoch 4/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.4656 - accuracy: 0.9442 - val_loss: 0.4250 - val_accuracy: 0.9531\n",
      "Epoch 5/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.3233 - accuracy: 0.9611 - val_loss: 0.3134 - val_accuracy: 0.9662\n",
      "Epoch 6/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.2220 - accuracy: 0.9737 - val_loss: 0.2363 - val_accuracy: 0.9760\n",
      "Epoch 7/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.1496 - accuracy: 0.9826 - val_loss: 0.1852 - val_accuracy: 0.9818\n",
      "Epoch 8/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.0994 - accuracy: 0.9886 - val_loss: 0.1495 - val_accuracy: 0.9860\n",
      "Epoch 9/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.0651 - accuracy: 0.9931 - val_loss: 0.1259 - val_accuracy: 0.9885\n",
      "Epoch 10/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.0456 - accuracy: 0.9953 - val_loss: 0.1090 - val_accuracy: 0.9901\n",
      "Epoch 11/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.0269 - accuracy: 0.9972 - val_loss: 0.0965 - val_accuracy: 0.9919\n",
      "Epoch 12/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.0172 - accuracy: 0.9988 - val_loss: 0.0873 - val_accuracy: 0.9938\n",
      "Epoch 13/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.0109 - accuracy: 0.9997 - val_loss: 0.0797 - val_accuracy: 0.9949\n",
      "Epoch 14/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.0067 - accuracy: 0.9999 - val_loss: 0.0749 - val_accuracy: 0.9955\n",
      "Epoch 15/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9957\n",
      "Epoch 16/20\n",
      "489/489 [==============================] - 38s 77ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9958\n",
      "Epoch 17/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 0.9959\n",
      "Epoch 18/20\n",
      "489/489 [==============================] - 38s 77ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 0.9959\n",
      "Epoch 19/20\n",
      "489/489 [==============================] - 38s 77ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 0.9959\n",
      "Epoch 20/20\n",
      "489/489 [==============================] - 38s 78ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x262f0d1d2e0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([X_train, y_train], np.expand_dims(y_train, -1), epochs=20, batch_size=64, validation_data=([X_val, y_val], np.expand_dims(y_val, -1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Inference and Prediction\n",
    "To use the model for inference, you need to define separate encoder and decoder models for predicting sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Input sentence: a girl going into a wooden building .\n",
      "Decoded sentence: একটি মেয়ে শিশু একটি কাঠের বাড়িতে ঢুকছে\n"
     ]
    }
   ],
   "source": [
    "# Encoder model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder model\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_embedding2 = Embedding(input_dim=num_decoder_tokens, output_dim=EMBEDDING_DIM)(decoder_inputs)\n",
    "decoder_lstm2, state_h2, state_c2 = LSTM(256, return_sequences=True, return_state=True)(decoder_embedding2, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h2, state_c2]\n",
    "decoder_outputs2 = TimeDistributed(Dense(num_decoder_tokens, activation='softmax'))(decoder_lstm2)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states)\n",
    "\n",
    "def preprocess_input_sentence(sentence):\n",
    "    sequence = source_tokenizer.texts_to_sequences([sentence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    return padded_sequence\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    start_token_index = target_tokenizer.word_index.get(START_TOKEN)\n",
    "    if start_token_index is None:\n",
    "        raise KeyError(f\"'{START_TOKEN}' not found in target_tokenizer.word_index\")\n",
    "    target_seq[0, 0] = start_token_index\n",
    "\n",
    "    decoded_sentence = ''\n",
    "    stop_condition = False\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = target_tokenizer.index_word.get(sampled_token_index, '')\n",
    "        if not sampled_char:\n",
    "            break\n",
    "        \n",
    "        decoded_sentence += sampled_char + ' '\n",
    "\n",
    "        if sampled_char == END_TOKEN or len(decoded_sentence) > MAX_SEQUENCE_LENGTH:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()\n",
    "\n",
    "input_sentence = 'a girl going into a wooden building .'\n",
    "input_seq = preprocess_input_sentence(input_sentence)\n",
    "try:\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(f'Input sentence: {input_sentence}')\n",
    "    print(f'Decoded sentence: {decoded_sentence}')\n",
    "except KeyError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
